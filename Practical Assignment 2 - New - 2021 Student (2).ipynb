{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NuJ0879WJF0E",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Names: ['Lucas Belderink', 'Rama Pamudji'] \n",
    "Studentnumbers: ['12151750', '11170220']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "wKpbQMIQJF0K",
    "nbgrader": {
     "checksum": "89914f38bf3510543caaef66d0f14169",
     "grade": false,
     "grade_id": "cell-700f4a41782fa412",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Applied Machine learning\n",
    "## Practical Assignment 2\n",
    "\n",
    "### Important Notes:\n",
    "1. Submit through **Canvas** before 11:59pm on Tuesday, May 11, 2021\n",
    "2. No late homework will be accepted\n",
    "3. This is a group-of-two assignment\n",
    "4. The submitted file should be in ipynb format\n",
    "5. The assignment is worth it 10 points\n",
    "6. For questions, please use the discussion part of Canvas (English only!)\n",
    "7. The indication **optional** means that the question is optional; you won't lose any points if you do not do that part of the assignment, nor will you gain if you do it.\n",
    "\n",
    "### Software:\n",
    "We will be using Python programming language throughout this course. Further we will be using:\n",
    "+ IPython Notebooks (as an environment)\n",
    "+ Numpy\n",
    "+ Pandas\n",
    "+ Scikit-learn\n",
    "\n",
    "### Background:\n",
    "\n",
    "This practical assignment will be covering logistic regression, neural networks, support vector machines and evaluation of classifiers. \n",
    "\n",
    "For the assignment, please download a dataset on Load Defaults. You are provided with two datasets:\n",
    "1. [Dataset](https://drive.google.com/open?id=1cj-CzkY6QZUe42ky64GI5CSSg7-K40N5) with 10,000 instances \n",
    "2. [Dataset](https://drive.google.com/open?id=1MbWGXLawE3VTxP1XgNpj8uEo1VHPq12B) with 100,000 instances\n",
    "In principle you should work on the second, larger dataset, but if you face scaling computational issues then better work with the first, smaller dataset.\n",
    "\n",
    "This data corresponds to a set of financial transactions associated with individuals. The data has been standardized, de-trended, and anonymized. You are provided with thousands of observations and nearly 800 features. Each observation (instance) is independent from the previous. \n",
    "\n",
    "For each observation, it was recorded whether a default was triggered. In case of a default, the loss was measured. This quantity lies between 0 and 100. It has been normalised, considering that the notional of each transaction at inception is 100. For example, a loss of 60 means that only 40 is reimbursed. If the loan did not default, the loss was 0. You are asked to predict the losses for each observation in the test set.\n",
    "\n",
    "Missing feature values have been kept as is, so that the competing teams can really use the maximum data available, implementing a strategy to fill the gaps if desired. Consider all variables continuous, even though some variables may be categorical (e.g. f776 and f777).\n",
    "\n",
    "The goal of the machine learning algorithm will be to predict whether a loan will default, given a set of features. For privacy reasons the feature names are not provided.\n",
    "\n",
    "**Important Note**: This second assignment is not as instructive as the first assignment. The first assignment guided you step-by-step through all the preprocessing, training-validation-testing setup, etc. This assignment does not do so, but it leaves it up to you to decide how to use the data and design your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10488,
     "status": "ok",
     "timestamp": 1618851213972,
     "user": {
      "displayName": "Mohammad Aliannejadi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPO1w_DfPwEKbrl4Dys5EnchJ-8auKnVWSrVpk1A=s64",
      "userId": "16397319799386146908"
     },
     "user_tz": -120
    },
    "id": "PHjzAhvgBlo7",
    "outputId": "c9cc7c86-23db-434d-fea1-b1b94a0e8f0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "# Dataset with 10K instances\n",
    "! gdown \"https://drive.google.com/uc?id=1cj-CzkY6QZUe42ky64GI5CSSg7-K40N5\"\n",
    "# Dataset with 100k instances\n",
    "! gdown \"https://drive.google.com/uc?id=1MbWGXLawE3VTxP1XgNpj8uEo1VHPq12B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in d:\\anaconda\\lib\\site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SlHJBPXQJF0K",
    "nbgrader": {
     "checksum": "86f687db575cf409d54ac5e91e6dd861",
     "grade": false,
     "grade_id": "cell-1979a89473cf7ece",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 1: Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "k63PQb_KJF0L",
    "nbgrader": {
     "checksum": "cdc9100b2eb32f795318f88531439408",
     "grade": false,
     "grade_id": "cell-3a36fe2e430fa9ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('loan_default_10K.csv', sep=\",\", header=0, dtype=np.float64)\n",
    "\n",
    "# Drop the observations that contain missing values\n",
    "dfn = df.dropna(0, how='any')\n",
    "\n",
    "# Consider only a handful of features to start with; you can extend to the full set later on.\n",
    "X = dfn.loc[:,'f400':'f500'].values\n",
    "\n",
    "# Generate the labels; if 'loss' is zero the this indicates the negative class, class 0, i.e. no default;\n",
    "# if 'loss' is possitive this indicates the positive class, class 1, i.e. there is a loan default;\n",
    "y = [ bool(y) for y in dfn.loc[:,'loss'].values ]\n",
    "\n",
    "# Separate the data into train, validation, and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tabulate import tabulate\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "\n",
    "\n",
    "predicted_y = [random.choice([True, False]) for x in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0LKlXxS3JF0L",
    "nbgrader": {
     "checksum": "ff730342a91fefa515c3117b502aa292",
     "grade": false,
     "grade_id": "cell-735be096b0f642ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2: Evaluation measures (2pts)\n",
    "In what follows you should implement a number of evaluation measures. You need to implement these from scratch, meaning that it is not allowed to call any scikit-learn function, or any other API function that implements the method for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4yvWH4cgJF0L",
    "nbgrader": {
     "checksum": "cdadfd696f9d159f0242cad28b7f41ef",
     "grade": false,
     "grade_id": "cell-a127e8413f617d64",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that produces the contigency matrix, i.e. True Positives, False Positives, True Negatives, False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "294-dY4BJF0M",
    "nbgrader": {
     "checksum": "bd892db60c7761bace1ca06b9361a045",
     "grade": false,
     "grade_id": "cell-aab0f82d6a21bea5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "1998\n",
      "1954\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def contingency_matrix(true_y, predicted_y):\n",
    "    count_tp = 0\n",
    "    count_tn = 0\n",
    "    count_fp = 0\n",
    "    count_fn = 0\n",
    "\n",
    "    for x in range(len(true_y)):\n",
    "        if true_y[x] == True and true_y[x] == predicted_y[x]:\n",
    "            count_tp+=1\n",
    "        if true_y[x] == False and true_y[x] == predicted_y[x]:\n",
    "            count_tn+=1\n",
    "        if true_y[x] == True and true_y[x] != predicted_y[x]:\n",
    "            count_fn+=1\n",
    "        if true_y[x] == False and true_y[x] != predicted_y[x]:\n",
    "            count_fp+=1\n",
    "#     print(\"TPs, fps \", [count_tp, count_fp])\n",
    "#     print(\"TNs, fns \", [count_tn, count_fn])\n",
    "#     print(np.array(([count_tp, count_fp], [count_tn, count_fn])))\n",
    "    \n",
    "    matrix = np.array(([count_tp, count_fp], [count_tn, count_fn]))\n",
    "\n",
    "    # Make sure your output fits the following format:\n",
    "    # matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix\n",
    "    \n",
    "print(contingency_matrix(y, predicted_y)[0][0])\n",
    "print(contingency_matrix(y, predicted_y)[0][1])\n",
    "print(contingency_matrix(y, predicted_y)[1][0])\n",
    "print(contingency_matrix(y, predicted_y)[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cV3BfX8jJF0M",
    "nbgrader": {
     "checksum": "b2f901219adca9d441082d3fcf702e6b",
     "grade": false,
     "grade_id": "cell-b3c52de1970e361e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes accuracy (without using any built-in accuracy function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "id": "DK2lCwiNJF0M",
    "nbgrader": {
     "checksum": "f6705877fef7cd74d89832d32a8536a0",
     "grade": false,
     "grade_id": "cell-2e0cc734628dd4c2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49690863292878407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49690863292878407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(true_y, predicted_y):\n",
    "    contingency = contingency_matrix(true_y, predicted_y)\n",
    "    \n",
    "    return (contingency[0][0] + contingency[1][0]) / len(predicted_y)\n",
    "\n",
    "    \n",
    "print(accuracy(y, predicted_y))\n",
    "sklearn.metrics.accuracy_score(y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4LznpIdTJF0M",
    "nbgrader": {
     "checksum": "4b3798ba720235065011afa2736346a7",
     "grade": false,
     "grade_id": "cell-d045e95a552112ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes precision  (without using any built-in precision function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "id": "QC8SeWOIJF0M",
    "nbgrader": {
     "checksum": "40f4c7470d6073739cff4934761469c8",
     "grade": false,
     "grade_id": "cell-a403be8ac0ee7af0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0975609756097561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0975609756097561"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision(true_y, predicted_y):\n",
    "    contingency = contingency_matrix(true_y, predicted_y)\n",
    "    \n",
    "    \n",
    "    if (contingency[0][0] + contingency[0][1]) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (contingency[0][0] / (contingency[0][0] + contingency[0][1]))\n",
    "    \n",
    "    \n",
    "print(precision(y, predicted_y))\n",
    "sklearn.metrics.precision_score(y, predicted_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_D7OYnK4JF0N",
    "nbgrader": {
     "checksum": "6dbe4298af11247615077250b24d3f59",
     "grade": false,
     "grade_id": "cell-4822b32d0cedb0e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes recall (without using any built-in recall function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "id": "X08ucQRFJF0N",
    "nbgrader": {
     "checksum": "cf41435f0b5003e31ae61340d3188bde",
     "grade": false,
     "grade_id": "cell-075963e37ff41c66",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5204819277108433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5204819277108433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(true_y, predicted_y):\n",
    "    contingency = contingency_matrix(true_y, predicted_y)\n",
    "\n",
    "    if (contingency[0][0] + contingency[1][1]) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (contingency[0][0] / (contingency[0][0] + contingency[1][1]))\n",
    "\n",
    "print(recall(y, predicted_y))\n",
    "sklearn.metrics.recall_score(y, predicted_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yE78OP9tJF0N",
    "nbgrader": {
     "checksum": "c0fa7903c66407fa515b5c4c5e12b266",
     "grade": false,
     "grade_id": "cell-f0c5ff30db6fc1b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function that computes f1 (without using any built-in f1 function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "FB-f5OO1JF0N",
    "nbgrader": {
     "checksum": "0b8095ecb0d05692b4a57cc17eff026d",
     "grade": false,
     "grade_id": "cell-bcc41b9d876ee5d4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16432103461392164\n"
     ]
    }
   ],
   "source": [
    "def f1(true_y, predicted_y):\n",
    "    prec = precision(true_y, predicted_y)\n",
    "    rec = recall(true_y, predicted_y)\n",
    "    \n",
    "    if (prec + rec) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * ((prec*rec)/(prec+rec)))\n",
    "\n",
    "print(f1(y, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jO5VhQLWJF0N",
    "nbgrader": {
     "checksum": "e0d9785e1e45e2179c318aec035059ad",
     "grade": false,
     "grade_id": "cell-c21fd73cbce64a50",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 3: Algorithms\n",
    "Compare the performance of Logistic Regression, Neural Networks, and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UWXjVAenJF0N",
    "nbgrader": {
     "checksum": "af0943a520201c48990805ce5cb2cb7c",
     "grade": false,
     "grade_id": "cell-7ea6f44ccf633c76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Logistic Regression (Lecture 3) (2pts)\n",
    "\n",
    "+ Train and test a logistic regression model\n",
    "    + Construct a table with each row being a different value of the regularization parameter and each column the aforementioned measures\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "id": "vnnZ6T1MJF0O",
    "nbgrader": {
     "checksum": "bb4b24cb9b3769517aafa02dce6321d4",
     "grade": true,
     "grade_id": "cell-eea85664ef370cd5",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C =  1  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.8  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.7  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.6  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.5  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.4  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.3  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.2  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.1  : \n",
      "True negatives:  3160\n",
      "False negatives:  332\n",
      "True positives:  1\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.05  : \n",
      "True negatives:  3160\n",
      "False negatives:  333\n",
      "True positives:  0\n",
      "False positives:  0\n",
      "\n",
      "Using C =  0.01  : \n",
      "True negatives:  3160\n",
      "False negatives:  333\n",
      "True positives:  0\n",
      "False positives:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "regparams = [1, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "\n",
    "for const in regparams:\n",
    "    print(\"Using C = \", const, \" : \")\n",
    "    log = LogisticRegression(random_state = 0, C = const, max_iter = 1000, solver = 'liblinear')\n",
    "    log.fit(X_train_scaled, y_train)\n",
    "    predictions = log.predict(X_train_scaled)\n",
    "\n",
    "    conf = confusion_matrix(y_train, predictions)\n",
    "    print(\"True negatives: \", conf[0][0])\n",
    "    print(\"False negatives: \", conf[1][0])\n",
    "    print(\"True positives: \", conf[1][1])\n",
    "    print(\"False positives: \", conf[0][1])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KNigDLF2JF0O",
    "nbgrader": {
     "checksum": "0d74b83486a9bcdcbdf539376bd56e52",
     "grade": false,
     "grade_id": "cell-f57d340c8ac3f3b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Explain what you observe regarding the positive class; i.e. the performance of the algorithm in predicting defaults. Explain why is this happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "NjRu6n9kJF0O",
    "nbgrader": {
     "checksum": "106a108640959c5f8b9523216dfc1ca2",
     "grade": true,
     "grade_id": "cell-75527f6a11293f5c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">The algorithm almost exclusively predicts negative classes. The negative class is far more frequent in the dataset (415 positive class cases, and 3952 negative class cases) which causes the logistic model to favour predicting a negative class far more frequently. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MZUnFZUxJF0O",
    "nbgrader": {
     "checksum": "847a1e00ad9d4316b9512efe1a66df26",
     "grade": false,
     "grade_id": "cell-f1d84ada7bb6859e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "There are a number of ways to fix the problem you have observed above. Here we will consider two of them: downsampling and upsampling. In an ideal situation you will like your dataset to be balanced, i.e. to have the same number of instances for the positive and the negative class.\n",
    "\n",
    "**Downsampling**: Let's assume that the positive class has *n1* instances, while the negative class *n2* instances, where *n2* is much bigger than *n1*. One solution is to create a new training set for which from the *n2* instances of the negative class you sample *n1* of them only to include in your training set; hence now you have *n1* + *n1* training instances.\n",
    "\n",
    "**Upsampling**: Let's assume that the positive class has *n1* instances, while the negative class *n2* instances, where *n2* is much bigger than *n1*. Another solution is to create a new training set for which you create  *n2* instances of the positive class. To do so you sample *n2* instances from the *n1* instance, with replacement. With replacement means that you allow the same instance to be sampled multiple times; hence now you have *n2* + *n2* training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "otj4Qm3MJF0O"
   },
   "source": [
    "#### Downsampling (OPTIONAL – If you wish to skip downsampling continue to Neural Networks further below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_sDkkIcUJF0O",
    "nbgrader": {
     "checksum": "ea6ec4f362d483b9439040f12d09b46a",
     "grade": false,
     "grade_id": "cell-59aa6ae849b90374",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Implement a function for downsampling (**optional**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "7L6yUCajJF0P",
    "nbgrader": {
     "checksum": "005c2fee650b5518f0d377e26d46615d",
     "grade": true,
     "grade_id": "cell-f111bc027ec54669",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3493\n",
      "666\n",
      "3493\n",
      "666\n",
      "333 333\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def downsample(y_train):\n",
    "    # y_train is the 1d matrix of the labels in your training data, e.g.\n",
    "    #       0     1     2     3     4   5     6     7     8   ... \n",
    "    # y = [True False False False True True False False False ... False]\n",
    "    #\n",
    "    # the function returns the position of the training data to be considered for the final training set.\n",
    "    # e.g. if you decide from the True instances to select 0, 4 and 5, while from the False instances 1, 3, and 8\n",
    "    # the outcome of the function will be [0, 1, 3, 4, 5, 8] (= sampled_indexes)\n",
    "    \n",
    "    positive_indexes = []\n",
    "    negative_indexes = []\n",
    "    \n",
    "    for i in range(0, len(y_train)):\n",
    "        if y_train[i] == True:\n",
    "            positive_indexes.append(i)\n",
    "        elif y_train[i] == False:\n",
    "            negative_indexes.append(i)\n",
    "         \n",
    "    if len(positive_indexes) > len(negative_indexes):\n",
    "        positive_indexes = random.sample(positive_indexes, len(negative_indexes))\n",
    "    elif len(negative_indexes) > len(positive_indexes):\n",
    "        negative_indexes = random.sample(negative_indexes, len(positive_indexes))\n",
    "        \n",
    "    sampled_indexes = sorted(positive_indexes + negative_indexes)\n",
    "\n",
    "    return sampled_indexes\n",
    "\n",
    "sampled_indexes = downsample(y_train)\n",
    "\n",
    "    \n",
    "def new_training_set(X_train, y_train, sampled_indexes):\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    \n",
    "    for index in sampled_indexes:\n",
    "        new_X.append(list(X_train[index]))\n",
    "        new_y.append(y_train[index])\n",
    "        \n",
    "    return new_X, new_y\n",
    "\n",
    "downsampled_X_train, downsampled_y_train = new_training_set(X_train_scaled, y_train, sampled_indexes)\n",
    "\n",
    "\n",
    "print(len(X_train_scaled))\n",
    "print(len(downsampled_X_train))\n",
    "print(len(y_train))\n",
    "print(len(downsampled_y_train))\n",
    "\n",
    "# Count the amount of positive and negative classes in the downsampled y_train dataset to show the downsampling\n",
    "# executed successfully.\n",
    "pos = 0\n",
    "neg = 0\n",
    "for item in downsampled_y_train:\n",
    "    if item == True:\n",
    "        pos += 1\n",
    "    elif item == False:\n",
    "        neg += 1\n",
    "        \n",
    "print(pos, neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "akjEu_5-JF0P",
    "nbgrader": {
     "checksum": "7acfd4fa50b0ce7567f3622b8df52dc9",
     "grade": false,
     "grade_id": "cell-0489481a9fc804d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Test the performance of logistic regression using the new training set, and report your conclusions (**optional**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "gYWgW2LOJF0P",
    "nbgrader": {
     "checksum": "8ef852228cb6d7212a28012d7e335ad1",
     "grade": true,
     "grade_id": "cell-cd7143b6e088d522",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  regularization C    Accuracy    Recall    Precision    F1 score\n",
      "------------------  ----------  --------  -----------  ----------\n",
      "            1e-05       0.3719    0.4024       0.4855      0.4401\n",
      "            0.0001      0.365     0.4234       0.4764      0.4483\n",
      "            0.001       0.381     0.4745       0.5         0.4869\n",
      "            0.01        0.3856    0.4775       0.5064      0.4915\n",
      "            0.05        0.3822    0.4535       0.5017      0.4763\n",
      "            0.1         0.3822    0.4565       0.5017      0.478\n",
      "            0.2         0.3787    0.4505       0.4967      0.4724\n",
      "            0.3         0.3833    0.4535       0.5033      0.4771\n",
      "            0.5         0.3856    0.4595       0.5066      0.4819\n",
      "            0.8         0.3856    0.4625       0.5066      0.4835\n",
      "            1           0.3856    0.4565       0.5067      0.4803\n",
      "            5           0.3799    0.4414       0.4983      0.4682\n",
      "           10           0.3867    0.4655       0.5082      0.4859\n",
      "          100           0.3902    0.4745       0.513       0.493\n",
      "         1000           0.3822    0.4655       0.5016      0.4829\n",
      "        10000           0.3696    0.4444       0.4837      0.4632\n"
     ]
    }
   ],
   "source": [
    "# regparams = [1, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "# regparams = [100000, 10000, 1000, 100, 10, 5, 1, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.01, 0.001, 0.0001, 0.00001]\n",
    "regparams = [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1, 5, 10, 100, 1000, 10000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for const in regparams:\n",
    "    log = LogisticRegression(random_state = 0, C = const, solver = 'liblinear')\n",
    "    log.fit(downsampled_X_train, downsampled_y_train)\n",
    "    predictions = log.predict(X_test_scaled)\n",
    "\n",
    "    acc = round(accuracy(downsampled_y_train, predictions), 4)\n",
    "    rec = round(recall(downsampled_y_train, predictions), 4)\n",
    "    prec = round(precision(downsampled_y_train, predictions), 4)\n",
    "    f1s = round(f1(downsampled_y_train, predictions), 4)\n",
    "#     print(acc, rec, prec, f1s)\n",
    "\n",
    "    tablerow = (const, acc, rec, prec, f1s)\n",
    "    results.append(tablerow)\n",
    "        \n",
    "print(tabulate(results, headers=[\"regularization C\", \"Accuracy\", \"Recall\", \"Precision\", \"F1 score\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">The downsampled results show the model still scores rather poorly for predictions, \n",
    "but significantly better than the model with a non-downsampled training set.\n",
    "We would like to add that the results still prioritized just a single classification, until we added scaling to\n",
    "the X set.\n",
    "The optimal configuration seems to be with regularization C = 0.001\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT1gcqt_JF0P"
   },
   "source": [
    "# The last few questions below are not optional!\n",
    "If you did not finish the optional downsampling, just go through with the data created before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YI7doqzLJF0P",
    "nbgrader": {
     "checksum": "fdac93da6191896d74c7346d2e875a84",
     "grade": false,
     "grade_id": "cell-4dc578274728380b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Neural Network (2pts)\n",
    "\n",
    "+ Train and test a Neural Network model\n",
    "    + Construct a table with each row being a different configuration of the network (play with the number of hidden layers, the number of neurons in each layer, and the activation function) and each column the evaluation measures\n",
    "    + Report the performance of at least three different configurations\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Justify your choice of different paramteres and architectures\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "Ac5mNYD3JF0P",
    "nbgrader": {
     "checksum": "167eed2eaafde3d4951aef9059e06a58",
     "grade": true,
     "grade_id": "cell-c6f93c6c6f633c47",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, colorConverter, LinearSegmentedColormap\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════════════════╤════════════╤═════════════╤══════════╤══════════╕\n",
      "│ Configuration                       │   Accuracy │   precision │   recall │       f1 │\n",
      "╞═════════════════════════════════════╪════════════╪═════════════╪══════════╪══════════╡\n",
      "│ l:4, n:(4, 3, 2, 1), logistic       │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(4, 3, 2, 1), relu           │  0.566362  │   0.122137  │ 0.585366 │ 0.202105 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(4, 3, 2, 1), tanh           │  0.62357   │   0.095082  │ 0.353659 │ 0.149871 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 5, 2, 1), logistic      │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 5, 2, 1), relu          │  0.394737  │   0.108581  │ 0.756098 │ 0.189893 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 5, 2, 1), tanh          │  0.622426  │   0.121951  │ 0.487805 │ 0.195122 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(50, 25, 10, 1), logistic    │  0.602975  │   0.122507  │ 0.52439  │ 0.198614 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(50, 25, 10, 1), relu        │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(50, 25, 10, 1), tanh        │  0.656751  │   0.110714  │ 0.378049 │ 0.171271 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(5, 8, 3, 4), logistic       │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(5, 8, 3, 4), relu           │  0.590389  │   0.120879  │ 0.536585 │ 0.197309 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(5, 8, 3, 4), tanh           │  0.450801  │   0.102     │ 0.621951 │ 0.175258 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1, 10, 100, 1), logistic    │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1, 10, 100, 1), relu        │  0.657895  │   0.077821  │ 0.243902 │ 0.117994 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1, 10, 100, 1), tanh        │  0.545767  │   0.109181  │ 0.536585 │ 0.181443 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 100, 1000, 1), logistic │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 100, 1000, 1), relu     │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(10, 100, 1000, 1), tanh     │  0.786041  │   0.132867  │ 0.231707 │ 0.168889 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 10, 100, 4), logistic │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 10, 100, 4), relu     │  0.44508   │   0.104126  │ 0.646341 │ 0.179357 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 10, 100, 4), tanh     │  0.480549  │   0.0866667 │ 0.47561  │ 0.146617 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 100, 10, 2), logistic │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 100, 10, 2), relu     │  0.525172  │   0.0987952 │ 0.5      │ 0.16499  │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:4, n:(1000, 100, 10, 2), tanh     │  0.544622  │   0.10101   │ 0.487805 │ 0.167364 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(5, 2, 1), logistic          │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(5, 2, 1), relu              │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(5, 2, 1), tanh              │  0.608696  │   0.110778  │ 0.45122  │ 0.177885 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(20, 10, 1), logistic        │  0.543478  │   0.114355  │ 0.573171 │ 0.190669 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(20, 10, 1), relu            │  0.561785  │   0.0965147 │ 0.439024 │ 0.158242 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(20, 10, 1), tanh            │  0.5       │   0.0900693 │ 0.47561  │ 0.151456 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(50, 25, 1), logistic        │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(50, 25, 1), relu            │  0.906178  │   0         │ 0        │ 0        │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:3, n:(50, 25, 1), tanh            │  0.627002  │   0.0960265 │ 0.353659 │ 0.151042 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(5, 1), logistic             │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(5, 1), relu                 │  0.0938215 │   0.0938215 │ 1        │ 0.171548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(5, 1), tanh                 │  0.542334  │   0.115942  │ 0.585366 │ 0.193548 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(10, 5), logistic            │  0.561785  │   0.117048  │ 0.560976 │ 0.193684 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(10, 5), relu                │  0.532037  │   0.0962963 │ 0.47561  │ 0.160164 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(10, 5), tanh                │  0.501144  │   0.0785714 │ 0.402439 │ 0.131474 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(100, 10), logistic          │  0.514874  │   0.107798  │ 0.573171 │ 0.181467 │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(100, 10), relu              │  0.520595  │   0.103529  │ 0.536585 │ 0.17357  │\n",
      "├─────────────────────────────────────┼────────────┼─────────────┼──────────┼──────────┤\n",
      "│ l:2, n:(100, 10), tanh              │  0.55492   │   0.101299  │ 0.47561  │ 0.167024 │\n",
      "╘═════════════════════════════════════╧════════════╧═════════════╧══════════╧══════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# self imagined layers with different neuron combinations\n",
    "layers = [(4,3,2,1), (10,5,2,1), (50,25,10,1), (5,8,3,4), (1,10,100,1), (10,100,1000,1), (1000,10,100,4), (1000,100,10,2), (5,2,1), (20,10,1), (50,25,1), (5,1), (10,5), (100,10)]\n",
    "act = ['logistic', 'relu', 'tanh']\n",
    "\n",
    "table = []\n",
    "\n",
    "for x in range(len(layers)):\n",
    "    for y in range(len(act)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=layers[x], activation=act[y])\n",
    "        mlp.fit(downsampled_X_train, downsampled_y_train)\n",
    "    \n",
    "        table.append([\"l:\"+str(len(layers[x]))+\", \"+\"n:\"+str(layers[x])+\", \"+act[y], accuracy_score(y_test, mlp.predict(X_test_scaled), normalize=True), \n",
    "          precision_score(y_test, mlp.predict(X_test_scaled)),\n",
    "         recall_score(y_test, mlp.predict(X_test_scaled)),\n",
    "                     f1_score(y_test, mlp.predict(X_test_scaled))])\n",
    "\n",
    "print(tabulate(table, headers=[\"Configuration\",\"Accuracy\",'precision','recall','f1'], tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "hte-UpsCJF0Q",
    "nbgrader": {
     "checksum": "2412fc015a280623635f3bf03e3fde9e",
     "grade": true,
     "grade_id": "cell-b4ae750d1154f837",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\"><span style=\"color:blue\">We will take a look at the following neural networks: (4 Layers, Neurons: 1000,10,100,4, activation = relu), ( 4 layers, neurons: 1,10,100,1, activation = tanh) and (2 layers, neurons = 5,1, activation = logistic)\\\n",
    "    \\\n",
    "**(4 Layers, Neurons: 1000,10,100,4, activation = relu)**\\\n",
    "This configuration was chosen because it was one of the few cases with an output of 4, the ReLU activation function and the varying neurons per layer. It was also chosen as the f1 score was relatively high compared to other configurations with ReLU activation functions with a score of 0.171582. The precision and recall scores were respectfully 0.106667 and 0.438356. These are relatively decent scores and they show that the amount of layers and neurons per layer were relatively effective but less accurate then some with an accuracy of 0.646453.\\\n",
    "    \\\n",
    "**( 4 layers, neurons: 1,10,100,1, activation = tanh)**\\\n",
    "This configuration was chosen because of the ascending neurons per layer, the output of 1 and the Tanh activation function.\n",
    "This configuration shows a relatively high f1 score compared to all other configuration with a f1 score of 0.19577. This also showed a very high recall score of 0.863014 but a lower precision score of 0.094546. The accuracy does show that it was less effective as it has an accuracy score of 0.298627.\\\n",
    "    \\\n",
    "**(2 layers, neurons = 5,1, activation = logistic)**\\\n",
    "This configuration was chosen because of it's 2 layers and logistic activation function. This also the most optimal configuration as it has a recall score of 0.726027, a precision score of 0.115217 and an accuracy score of 0.511442. Overall the precision and recall scores were both higher than all other configurations and it has a relatively high accuracy score making it the most optimal configuration.\\\n",
    "\\\n",
    "The configuration **(2 layers, neurons = 5,1, activation = logistic)** was the most optimal as shown by the precision-, recall- and accuracy score of respectfully 0.115217, 0.726027 and 0.511442. This is due to the fact that there is no hidden layer and a small amount of neurons which prevent overfitting but could also potentially lead to underfitting. So in all fairness the configuration **(4 layers, neurons = 1000,10,100,4 activation = tanh)** with a slightly less better accuracy, precision and recall score of respectfully 0.529748, 0.112385 and 0.671233. This score shows a good performance and shows that it is a quite effective configuration for a configuration with 2 hidden layers and a large set of neurons. \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5DL60WojJF0Q",
    "nbgrader": {
     "checksum": "88788580e9ea0cc74560a55c6231466b",
     "grade": false,
     "grade_id": "cell-d7e21719abffa28b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### SVMs (2pts)\n",
    "\n",
    "+ Train and test a Support Vector Machine model\n",
    "    + Construct a table with each row being a different configuration of the SVM algorithm (play with the regularization parameter, and the kernel function – use linear, poly, and rbf) and each column the evaluation measures\n",
    "    + Explain your findings and select the optimal model\n",
    "    + Report the performance of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218 132]\n",
      " [201 115]]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Scores using C = \", const, \" :\")\n",
    "# print(\"_____________________________________________________\")\n",
    "# print(\"accuracy: \", accuracy(downsampled_y_train, svm_predictions))\n",
    "# print(\"recall: \", recall(downsampled_y_train, svm_predictions))\n",
    "# print(\"precision: \", precision(downsampled_y_train, svm_predictions))\n",
    "# print(\"f1: \", f1(downsampled_y_train, svm_predictions))\n",
    "# print(\"\")\n",
    "\n",
    "svm_model = svm.SVC(C = 1, kernel = \"linear\")\n",
    "svm_model.fit(downsampled_X_train, downsampled_y_train)\n",
    "\n",
    "svm_predictions = svm_model.predict(downsampled_X_train)\n",
    "\n",
    "contingency = contingency_matrix(downsampled_y_train, svm_predictions)\n",
    "# print(svm_predictions)\n",
    "print(contingency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "YWgD6iFmJF0Q",
    "nbgrader": {
     "checksum": "e4d7a215763017f7111a6162d214ed5e",
     "grade": true,
     "grade_id": "cell-7009d775455986ad",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel      regularization C    Accuracy    Recall    Precision    F1 score\n",
      "--------  ------------------  ----------  --------  -----------  ----------\n",
      "linear                1e-05       0.7723    0.1463       0.0851      0.1076\n",
      "linear                0.0001      0.7723    0.1463       0.0851      0.1076\n",
      "linear                0.001       0.5641    0.561        0.1176      0.1945\n",
      "linear                0.01        0.54      0.5976       0.1172      0.196\n",
      "linear                0.05        0.5366    0.4756       0.0973      0.1615\n",
      "linear                0.1         0.5309    0.4756       0.0961      0.1598\n",
      "linear                0.2         0.5286    0.4634       0.0936      0.1557\n",
      "linear                0.3         0.5286    0.5          0.0995      0.166\n",
      "linear                0.5         0.5309    0.5          0.1         0.1667\n",
      "linear                0.8         0.5195    0.5          0.0976      0.1633\n",
      "linear                1           0.5286    0.5          0.0995      0.166\n",
      "linear                5           0.5309    0.5          0.1         0.1667\n",
      "linear               10           0.5366    0.5          0.1012      0.1684\n",
      "linear              100           0.532     0.5732       0.1116      0.1869\n",
      "poly                  1e-05       0.9005    0            0           0\n",
      "poly                  0.0001      0.9005    0            0           0\n",
      "poly                  0.001       0.9005    0            0           0\n",
      "poly                  0.01        0.8822    0.0366       0.1111      0.055\n",
      "poly                  0.05        0.8238    0.1098       0.1         0.1047\n",
      "poly                  0.1         0.8021    0.122        0.0901      0.1036\n",
      "poly                  0.2         0.7334    0.2195       0.0963      0.1338\n",
      "poly                  0.3         0.7334    0.2317       0.1005      0.1402\n",
      "poly                  0.5         0.6911    0.2927       0.1017      0.1509\n",
      "poly                  0.8         0.595     0.4146       0.1         0.1611\n",
      "poly                  1           0.5481    0.5122       0.1058      0.1754\n",
      "poly                  5           0.5755    0.5122       0.1126      0.1846\n",
      "poly                 10           0.6041    0.4268       0.1048      0.1683\n",
      "poly                100           0.5229    0.4634       0.0925      0.1542\n",
      "rbf                   1e-05       0.5801    0.4512       0.1031      0.1678\n",
      "rbf                   0.0001      0.5801    0.4512       0.1031      0.1678\n",
      "rbf                   0.001       0.5801    0.4512       0.1031      0.1678\n",
      "rbf                   0.01        0.5801    0.4512       0.1031      0.1678\n",
      "rbf                   0.05        0.5801    0.4512       0.1031      0.1678\n",
      "rbf                   0.1         0.5446    0.5366       0.1089      0.1811\n",
      "rbf                   0.2         0.5092    0.5732       0.1066      0.1797\n",
      "rbf                   0.3         0.4977    0.5976       0.1077      0.1825\n",
      "rbf                   0.5         0.4966    0.5854       0.1057      0.1791\n",
      "rbf                   0.8         0.4977    0.6098       0.1094      0.1855\n",
      "rbf                   1           0.5183    0.5854       0.1103      0.1857\n",
      "rbf                   5           0.5721    0.5244       0.1138      0.187\n",
      "rbf                  10           0.5824    0.5122       0.1144      0.1871\n",
      "rbf                 100           0.508     0.5          0.0953      0.1602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# regparams = [1, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4]\n",
    "# regparams = [10000, 1000, 100, 10, 5, 1, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.01, 0.001, 0.0001, 0.00001]\n",
    "regparams = [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1, 5, 10, 100]\n",
    "\n",
    "kernels = [\"linear\", \"poly\", \"rbf\"]\n",
    "\n",
    "resultsSVM = []\n",
    "\n",
    "for kern in kernels:\n",
    "    for const in regparams:    \n",
    "        svm_model = svm.SVC(C = const, kernel = kern)\n",
    "        svm_model.fit(downsampled_X_train, downsampled_y_train)\n",
    "\n",
    "        svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "        acc = round(accuracy(y_test, svm_predictions), 4)\n",
    "        rec = round(recall(y_test, svm_predictions), 4)\n",
    "        prec = round(precision(y_test, svm_predictions), 4)\n",
    "        f1s = round(f1(y_test, svm_predictions), 4)\n",
    "\n",
    "        tablerow = (kern, const, acc, rec, prec, f1s)\n",
    "        resultsSVM.append(tablerow)\n",
    "        \n",
    "print(tabulate(resultsSVM, headers=[\"Kernel\", \"regularization C\", \"Accuracy\", \"Recall\", \"Precision\", \"F1 score\"]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "Pw5mJ1z1JF0Q",
    "nbgrader": {
     "checksum": "36cda951bae6da0700d3f6202d0f1a89",
     "grade": true,
     "grade_id": "cell-42c8bf3a6a671fef",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">Overall the model scores rather poorly. The highest accuracy score is reached by the poly kernel with C ~= 0.05. But this is accompanied with the other scores being very low for this case.\n",
    "The scores of the poly kernel seem to deviate the most overall with the different regularization scores.\n",
    "Precision scores are generally low across the board.\n",
    "The linear kernel scores pretty well at low regularization (high C) but is outclassed by the rbf kernel.\n",
    "The highest scoring combination of parameters seems to be the rdf kernel with C = 0.1.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OIgJSXMTJF0Q",
    "nbgrader": {
     "checksum": "baabfebe46559e2d055cef7ceae38b0e",
     "grade": false,
     "grade_id": "cell-23280b034d299667",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Compare Algorithms (2pts)\n",
    "* Plot the Precision-Recall curves for the best model for each one of the above algorithms, Logistic Regression, Neural Nets, and SVM.\n",
    "    * Use the precision_recall_curve from scikit-learn\n",
    "* Explain your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.11')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "log = LogisticRegression(random_state = 0, C = 0.001, solver = 'liblinear')\n",
    "log.fit(downsampled_X_train, downsampled_y_train)\n",
    "log_predictions = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, log_predictions)\n",
    "\n",
    "disp = plot_precision_recall_curve(log, X_test_scaled, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.10')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = layers[6], activation = act[2])\n",
    "mlp.fit(downsampled_X_train, downsampled_y_train)\n",
    "\n",
    "mlp_predictions = mlp.predict(X_test_scaled)\n",
    "\n",
    "average_precisionmlp = average_precision_score(y_test, mlp_predictions)\n",
    "\n",
    "disp = plot_precision_recall_curve(mlp, X_test_scaled, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precisionmlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "id": "8kRDcyLuJF0Q",
    "nbgrader": {
     "checksum": "b17597ab95452fa3d4259cb4d2bee6c2",
     "grade": true,
     "grade_id": "cell-d6967e3b3e3dbe7a",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.10')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_model = svm.SVC(C = 0.1, kernel = 'rbf')\n",
    "svm_model.fit(downsampled_X_train, downsampled_y_train)\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "average_precisionsvm = average_precision_score(y_test, svm_predictions)\n",
    "\n",
    "disp = plot_precision_recall_curve(svm_model, X_test_scaled, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precisionsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "_vShAj6OJF0Q",
    "nbgrader": {
     "checksum": "58ca34644cf139f5987905e2058ea0b3",
     "grade": true,
     "grade_id": "cell-b91319845bc74219",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "Out of the three models, the SVC seems to score the worst, but not by a large margin.\n",
    "The highest scoring model is the neural network, with logistic regression coming in a close second.\n",
    "\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Practical Assignment 2 - 2021 Student.ipynb ",
   "provenance": [
    {
     "file_id": "17ja4GM2Ci0MjQjO3RjTNBS0wcnLBpBIr",
     "timestamp": 1618862623296
    },
    {
     "file_id": "1tO5F-kPHZPpMGLNuPjfNqd3rXU1Lkmn1",
     "timestamp": 1618842712618
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
