{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6FWRjitH_lH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-575272ac8c88383d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Applied Machine Learning\n",
    "## Practical Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UB7sl_nQH_lL",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Names: ['Lucas Belderink', 'Rama Pamudji'] \n",
    "Studentnumbers: ['12151750', '11170220']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JnevPdzdZo6",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8b3a90e3eadc324",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Important Notes:\n",
    "1. Submit through **Canvas** before 11:59pm on Tuesday, April 20, 2021.\n",
    "2. No late homework will be accepted.\n",
    "3. This is a **group-of-two** assignment; hence choose **one** partner to work with.\n",
    "4. The submitted file should be in ipynb format\n",
    "5. The assignment is worth 10 points\n",
    "6. For questions, please use the discussion part of canvas (English only!)\n",
    "\n",
    "### Software:\n",
    "We will be using Python programming language throughout this course. Further we will be using:\n",
    "+ IPython Notebooks (as an environment)\n",
    "+ Numpy\n",
    "+ Pandas\n",
    "+ Scikit-learn\n",
    "\n",
    "\n",
    "### Background:\n",
    "\n",
    "This practical assignment will be covering linear regression and evaluation. For the assignment, please download a [dataset](https://drive.google.com/open?id=1rESPdl7CUfvgkA44YQ42pcOaMOCGN8B6) containing demographic information and crime statistics (in a given year) for some cities in the US.\n",
    "\n",
    "Assume that for certain cities there is missing information about crimes, so we would like to learn how to estimate the number of non-violent crimes based on characteristics of the city (demographics, location etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MeIfqiTVH_lM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f55bc95980e83e55",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from nose.tools import assert_count_equal, assert_equal\n",
    "from numpy.testing import *\n",
    "from pandas.testing import assert_frame_equal\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYWhz0bxdZo9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8452bfe549fa98ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Loading the data into a Pandas Data Frame [0.5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT64QznGH_lN"
   },
   "source": [
    "The descriptions of the columns of the dataset can be found here:\n",
    "\n",
    "**pop**: population\n",
    "\n",
    "**pctUrban**: percentage of people living in areas classified as urban\n",
    "\n",
    "**medIncome**: Median Income\n",
    "\n",
    "**pct12-29**: percentage of population that is 12-21 in age\n",
    "\n",
    "**pct65up**: percentage of population that is 65 and over in age\n",
    "\n",
    "**pctPoverty**: percentage of people under the poverty level\n",
    "\n",
    "**pctAllDivorc**: percentage of population who are divorced\n",
    "\n",
    "**pctUnemploy**: percentage of people 16 and over, in the labor force, and unemployed\n",
    "\n",
    "**perHoush**: mean persons per household\n",
    "\n",
    "**pctHousOccup**: percent of housing occupied\n",
    "\n",
    "**persHomeless**: number of homeless people\n",
    "\n",
    "**persEmergShelt**: number of people in homeless shelters\n",
    "\n",
    "**nonViolPerPop**: total number of non-violent crimes per 100K popuation\n",
    "\n",
    "**State**: the state in which this town/city is located\n",
    "\n",
    "**countyCode**: the code number of the county of the state this town/city is located\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssuDiTXHH_lN"
   },
   "source": [
    "\n",
    "### Question 1a:\n",
    "Load the data into a Pandas DataFrame. At this point, make sure that you only load the following columns: \n",
    "\n",
    "`'pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', 'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', 'persEmergShelt', 'nonViolPerPop'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "45PfGbv9H_lN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "csv_path = 'crime_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m-eINyWsH_lN",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a5813b911a397d1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct65up</th>\n",
       "      <th>pctPoverty</th>\n",
       "      <th>pctAllDivorc</th>\n",
       "      <th>pctUnemploy</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pctHousOccup</th>\n",
       "      <th>persHomeless</th>\n",
       "      <th>persEmergShelt</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11980.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75122.0</td>\n",
       "      <td>21.44</td>\n",
       "      <td>11.33</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.47</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.10</td>\n",
       "      <td>98.37</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23123.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.30</td>\n",
       "      <td>17.18</td>\n",
       "      <td>3.98</td>\n",
       "      <td>5.42</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.82</td>\n",
       "      <td>97.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.53</td>\n",
       "      <td>12.65</td>\n",
       "      <td>29.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>9.08</td>\n",
       "      <td>2.76</td>\n",
       "      <td>92.45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28700.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>27.41</td>\n",
       "      <td>14.42</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.64</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.60</td>\n",
       "      <td>95.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1890.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74111.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.16</td>\n",
       "      <td>8.58</td>\n",
       "      <td>13.68</td>\n",
       "      <td>8.64</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.46</td>\n",
       "      <td>95.07</td>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>4747.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pop  pctUrban  medIncome  pct12-29  pct65up  pctPoverty  pctAllDivorc  \\\n",
       "0  11980.0     100.0    75122.0     21.44    11.33        1.96          4.47   \n",
       "1  23123.0     100.0        NaN     21.30    17.18        3.98          5.42   \n",
       "2      NaN       0.0        NaN     40.53    12.65       29.99          9.73   \n",
       "3  28700.0     100.0    42805.0     27.41    14.42        4.01          7.64   \n",
       "4  74111.0     100.0        NaN     35.16     8.58       13.68          8.64   \n",
       "\n",
       "   pctUnemploy  perHoush  pctHousOccup  persHomeless  persEmergShelt  \\\n",
       "0         2.70      3.10         98.37             0              11   \n",
       "1         2.43      2.82         97.15             0               0   \n",
       "2         9.08      2.76         92.45             0               2   \n",
       "3         4.85      2.60         95.11             0               0   \n",
       "4         4.18      2.46         95.07            15             125   \n",
       "\n",
       "   nonViolPerPop  \n",
       "0        1394.59  \n",
       "1        1955.95  \n",
       "2        9988.79  \n",
       "3        1890.88  \n",
       "4        4747.58  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "crime_data = pd.read_csv(csv_path)[['pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', \n",
    "                       'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', \n",
    "                       'persEmergShelt', 'nonViolPerPop']]\n",
    "### END SOLUTION\n",
    "\n",
    "print(crime_data.shape)\n",
    "crime_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq2stRMtH_lO",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-793ac60698061e82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1b:\n",
    "We want to predict the number of crimes. Identify the features X and the target variable Y, and turn the X and Y DataFrames into Numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_FzIEG5DdZo-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8eb698d0c3f532fd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = crime_data[['pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', \n",
    "                'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', \n",
    "                'persEmergShelt']].to_numpy()\n",
    "\n",
    "Y = crime_data['nonViolPerPop'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9YvTy9kdZpG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-afc0b6593e782894",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Split the data into a training set and a test set [0.5 pts]\n",
    "### Question 2:\n",
    "Split the data into a training and a test set. Use a  70%-30% split.  \n",
    "Print the number of examples in the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e_oiLoaWdZpH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb09606197bd3f58",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11388\n",
      "7968\n",
      "3420\n",
      "0.6996838777660696\n",
      "0.30031612223393045\n",
      "\n",
      "\n",
      "949\n",
      "664\n",
      "285\n",
      "0.6996838777660696\n",
      "0.30031612223393045\n"
     ]
    }
   ],
   "source": [
    "X_train = 'Replace this string with the correct answer'\n",
    "X_test = 'Replace this string with the correct answer'\n",
    "Y_train = 'Replace this string with the correct answer'\n",
    "Y_test = 'Replace this string with the correct answer'\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X.size)\n",
    "print(X_train.size)\n",
    "print(X_test.size)\n",
    "\n",
    "print(X_train.size/X.size)\n",
    "print(X_test.size/X.size)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(Y.size)\n",
    "print(Y_train.size)\n",
    "print(Y_test.size)\n",
    "\n",
    "print(Y_train.size/Y.size)\n",
    "print(Y_test.size/Y.size)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIYFfQN0dZpM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-473a187a1ce777d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Linear Regression [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prbPvQZodZpN",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5db55cc890570964",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Missing Data**: Often the data you are considering is incomplete. For example in some city, the number of homeless people might be unknown. In this case, if you look into the datasets you will find the value *NaN*. This is not a real value, hence Linear Regression cannot handle it.\n",
    "\n",
    "The question is how can we handle missing data. There are many ways to do so, some more sophisticated than others. Here we will use a simple approach. This simple approach fills in the missing values, i.e. replaces the *NaN* by the median of the corresponding feature. E.g. if there is a *NaN* value for the population in one city, this *NaN* value will be replaced by the median number of the population in all other cities in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DZEv4VfCdZpP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0777a154778f1fe3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the missing data in the dataset (i.e. replace NaN values) \n",
    "\n",
    "def replace_nan_median(data):\n",
    "    medians_data = np.nanmedian(data, axis = 0)\n",
    "    \n",
    "    for y in range(0, len(data[0])):\n",
    "        for x in range(0, len(data)):\n",
    "            if pd.isnull(data[x, y]):\n",
    "                data[x, y] = medians_data[y]\n",
    "\n",
    "replace_nan_median(X_train)\n",
    "replace_nan_median(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XjCdj7VH_lP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f6424ae3678e3c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3a:\n",
    "Train a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BQc0v7GCdZpV",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-40087f3cfc1918c7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pop</td>\n",
       "      <td>-0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pctUrban</td>\n",
       "      <td>7.574894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medIncome</td>\n",
       "      <td>0.009905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pct12-29</td>\n",
       "      <td>-17.271344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pct65up</td>\n",
       "      <td>22.175874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pctPoverty</td>\n",
       "      <td>136.218690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pctAllDivorc</td>\n",
       "      <td>369.578949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pctUnemploy</td>\n",
       "      <td>-121.199664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>perHoush</td>\n",
       "      <td>493.756994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pctHousOccup</td>\n",
       "      <td>-37.212039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>persHomeless</td>\n",
       "      <td>-4.554693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>persEmergShelt</td>\n",
       "      <td>3.671601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  coefficient\n",
       "0              pop    -0.003027\n",
       "1         pctUrban     7.574894\n",
       "2        medIncome     0.009905\n",
       "3         pct12-29   -17.271344\n",
       "4          pct65up    22.175874\n",
       "5       pctPoverty   136.218690\n",
       "6     pctAllDivorc   369.578949\n",
       "7      pctUnemploy  -121.199664\n",
       "8         perHoush   493.756994\n",
       "9     pctHousOccup   -37.212039\n",
       "10    persHomeless    -4.554693\n",
       "11  persEmergShelt     3.671601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_linregmodel(X, Y):\n",
    "    lr = linear_model.LinearRegression()    \n",
    "    lr.fit(X, Y)\n",
    "    \n",
    "    return lr\n",
    "\n",
    "linreg_model = train_linregmodel(X_train, Y_train)\n",
    "\n",
    "\n",
    "coefs = pd.DataFrame()\n",
    "coefs['feature'] = crime_data[['pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', \n",
    "                'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', \n",
    "                'persEmergShelt']].columns\n",
    "coefs['coefficient'] = linreg_model.coef_\n",
    "\n",
    "display(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50pojKg3H_lP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71f736155f84e035",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3b:\n",
    "Compare the importance of features based on the parameters $\\theta$ of the model. \n",
    "\n",
    "1. Which are the top-5 most important features for the predicting the number of crimes per capita?   \n",
    "2. Out of those, which correlate positively and which negatively with the number of crimes in a region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bj9zdu3IH_lP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b020283aa02adae",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>perHoush</td>\n",
       "      <td>493.756994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pctAllDivorc</td>\n",
       "      <td>369.578949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pctPoverty</td>\n",
       "      <td>136.218690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pctUnemploy</td>\n",
       "      <td>-121.199664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pctHousOccup</td>\n",
       "      <td>-37.212039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  coefficient\n",
       "8      perHoush   493.756994\n",
       "6  pctAllDivorc   369.578949\n",
       "5    pctPoverty   136.218690\n",
       "7   pctUnemploy  -121.199664\n",
       "9  pctHousOccup   -37.212039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        perHoush\n",
      "2    pctAllDivorc\n",
      "3      pctPoverty\n",
      "4     pctUnemploy\n",
      "5    pctHousOccup\n",
      "Name: feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "coefs = coefs.reindex(coefs.coefficient.abs().sort_values(ascending = False).index)\n",
    "display(coefs[:5])\n",
    "\n",
    "top5 = coefs[:5]['feature']\n",
    "top5.index = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(top5)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e16W9xIcdZpg"
   },
   "source": [
    "<span style=\"color:blue\">**Replace the text in this cell with your explanation (if needed)**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsCghIl3H_lP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02ef93cfecd6a92f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3c:\n",
    "\n",
    "Compute the Mean Absolute Error and Root Mean Squared Error, do this without using the scikit-learn API for these values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D1wWlXgcdZpk",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9e0e18c6ac6a823",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  2375.864826477729\n",
      "Sklearn rmse:  2375.864826477729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "prediction = linreg_model.predict(X_test)\n",
    "actual_values = Y_test\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(\"Inputs hebben niet dezelfde lengte\")\n",
    "        \n",
    "    n = len(y_pred)\n",
    "\n",
    "    squared_errors = 0\n",
    "    for i in range(0, n):\n",
    "        squared_errors += (y_true[i] - y_pred[i])**2\n",
    "        \n",
    "    mse = squared_errors/n    \n",
    "    RMSE = mse**0.5\n",
    "    \n",
    "    return RMSE\n",
    "\n",
    "print(\"rmse: \", rmse(actual_values, prediction))\n",
    "test = mean_squared_error(actual_values, prediction)\n",
    "print(\"Sklearn rmse: \", test**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BBb38MXFH_lQ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286.4839271744945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mae(y_true, y_pred):\n",
    "\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(\"Inputs hebben niet dezelfde lengte\")\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    mean_errors = 0\n",
    "    for i in range(0, n):\n",
    "        mean_errors += np.absolute(y_true[i] - y_pred[i])\n",
    "\n",
    "    MAE = mean_errors/n\n",
    "\n",
    "    return MAE\n",
    "\n",
    "mae(actual_values, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-htxVRadZpp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff9572a7060b40ee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3d:\n",
    "MAE is an L1 error, while RMSE is an L2 error (L2 errors are based on the squared errors of each prediction in contrast to L1). Consider a scenario where having a relatively small deviation from the true value is ok, but you would really like to avoid making large errors in predictions. Which of those two metrics would you choose to evaluate your models? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCr2CzPNdZpx"
   },
   "source": [
    "<span style=\"color:blue\">These large prediction errors (large deviations from the true values, so outliers) will be magnified if squared alongside the other errors. These large prediction errors will increase the eventual values that represent your deviation (in this case RMSE) by too much, causing the outliers to make the RMSE values to be unrepresentative of the actual overall deviaton.\n",
    "If these outliers are present, L1 error would take them into account better than the squared errors method of L2.\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waQHGkwzdZpy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-880a51e909914143",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 4. Adding features [2 pts]\n",
    "1. Add a number of features by including polynomials and interactions of different degree\n",
    "2. Train and test the different linear regression models over the data\n",
    "3. Test whether increasing the complexity of the model overfits the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZCylJThdZqD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c953b9943fce092",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4a\n",
    "Implement a function that constructs additional features by considering the polynomials of the original features along with their interactions. Degree is the degree of the polynomial.  \n",
    "Consider the original dataset that was loaded into Pandas, and then turned into a Numpy array from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UPxirRI_dZqF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b1c89bb3ea71cd3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 1.4396e+04 1.0000e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.3030e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.4363e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.0000e+00 2.0999e+04 7.5480e+01 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.8310e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.3748e+04 7.4450e+01 ... 0.0000e+00 0.0000e+00 0.0000e+00]] [[1.0000e+00 2.7244e+04 7.0760e+01 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.2353e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 1.9600e+02]\n",
      " [1.0000e+00 1.7637e+04 1.0000e+02 ... 0.0000e+00 0.0000e+00 4.9000e+01]\n",
      " ...\n",
      " [1.0000e+00 4.7025e+04 1.0000e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 4.1856e+04 1.0000e+02 ... 1.0000e+00 1.1300e+02 1.2769e+04]\n",
      " [1.0000e+00 3.1287e+04 1.0000e+02 ... 0.0000e+00 0.0000e+00 6.4000e+01]]\n",
      "(664, 12)\n",
      "(664, 91)\n"
     ]
    }
   ],
   "source": [
    "def polynomial(X, degree):    \n",
    "    X_poly = PolynomialFeatures(degree).fit(X)\n",
    "    \n",
    "    return X_poly\n",
    "\n",
    "X_polynomial = polynomial(X_train, 2)\n",
    "x_train = X_polynomial.transform(X_train)\n",
    "x_test = X_polynomial.transform(X_test)\n",
    "\n",
    "print(x_train, x_test)\n",
    "\n",
    "dataset = pd.DataFrame(x_train)\n",
    "\n",
    "\n",
    "# convert the array back to a dataframe\n",
    "# dataset = pd.DataFrame(X_polynomial)\n",
    "# summarize\n",
    "print(X_train.shape)\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSmT1E-TdZqV",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9962d8a34afca4c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4b:\n",
    "Write your conclusions regarding the performance of the models of increasing complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OJ8eBIbOdZqM",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dc744bd0d05ecf76",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree 1 RMSE:  1510.6666616747175\n",
      "\n",
      "Degree 2 RMSE:  1225.4843223481769\n",
      "\n",
      "Degree 3 RMSE:  1129.41599793932\n",
      "\n",
      "Degree 4 RMSE:  1720.089943160478\n",
      "\n",
      "Degree 5 RMSE:  1838.9343590347542\n",
      "\n",
      "Degree 1 R^2:  0.5200539500927231\n",
      "\n",
      "Degree 2 R^2:  0.6841574401025243\n",
      "\n",
      "Degree 3 R^2:  0.7317356257194367\n",
      "\n",
      "Degree 4 R^2:  0.3777606889740156\n",
      "\n",
      "Degree 5 R^2:  0.2888068152050385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aac16cf088>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Generate polynomial dataset (both training and test) of degrees 1, 2, 3, 4, 5\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "'''DEGREE 1'''\n",
    "X_poly1 = polynomial(X_train, 1)\n",
    "X_trainpoly1 = X_poly1.transform(X_train)\n",
    "X_testpoly1 = X_poly1.transform(X_test)\n",
    "\n",
    "'''DEGREE 2'''\n",
    "X_poly2 = polynomial(X_train, 2)\n",
    "X_trainpoly2 = X_poly2.transform(X_train)\n",
    "X_testpoly2 = X_poly2.transform(X_test)\n",
    "\n",
    "'''DEGREE 3'''\n",
    "X_poly3 = polynomial(X_train, 3)\n",
    "X_trainpoly3 = X_poly3.transform(X_train)\n",
    "X_testpoly3 = X_poly3.transform(X_test)\n",
    "\n",
    "'''DEGREE 4'''\n",
    "X_poly4 = polynomial(X_train, 4)\n",
    "X_trainpoly4 = X_poly4.transform(X_train)\n",
    "X_testpoly4 = X_poly4.transform(X_test)\n",
    "\n",
    "'''DEGREE 5'''\n",
    "X_poly5 = polynomial(X_train, 5)\n",
    "X_trainpoly5 = X_poly5.transform(X_train)\n",
    "X_testpoly5 = X_poly5.transform(X_test)\n",
    "\n",
    "# Scale all features using the RobustScaler\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "'''DEGREE 1'''\n",
    "X_trainscaledpolytransformer1 = RobustScaler().fit(X_trainpoly1)\n",
    "X_trainscaledpoly1 = X_trainscaledpolytransformer1.transform(X_trainpoly1)\n",
    "\n",
    "# X_testscaledpolytransformer1 = RobustScaler().fit(X_testpoly1)\n",
    "# X_testscaledpoly1 = X_testscaledpolytransformer1.transform(X_testpoly1)\n",
    "\n",
    "# print(X_trainscaledpoly1)\n",
    "# print(len(X_testscaledpoly1))\n",
    "\n",
    "'''DEGREE 2'''\n",
    "X_trainscaledpolytransformer2 = RobustScaler().fit(X_trainpoly2)\n",
    "X_trainscaledpoly2 = X_trainscaledpolytransformer2.transform(X_trainpoly2)\n",
    "\n",
    "X_testscaledpolytransformer2 = RobustScaler().fit(X_testpoly2)\n",
    "X_testscaledpoly2 = X_testscaledpolytransformer2.transform(X_testpoly2)\n",
    "\n",
    "'''DEGREE 3'''\n",
    "X_trainscaledpolytransformer3 = RobustScaler().fit(X_trainpoly3)\n",
    "X_trainscaledpoly3 = X_trainscaledpolytransformer3.transform(X_trainpoly3)\n",
    "\n",
    "X_testscaledpolytransformer3 = RobustScaler().fit(X_testpoly3)\n",
    "X_testscaledpoly3 = X_testscaledpolytransformer3.transform(X_testpoly3)\n",
    "\n",
    "'''DEGREE 4'''\n",
    "X_trainscaledpolytransformer4 = RobustScaler().fit(X_trainpoly4)\n",
    "X_trainscaledpoly4 = X_trainscaledpolytransformer4.transform(X_trainpoly4)\n",
    "\n",
    "X_testscaledpolytransformer4 = RobustScaler().fit(X_testpoly4)\n",
    "X_testscaledpoly4 = X_testscaledpolytransformer4.transform(X_testpoly4)\n",
    "\n",
    "'''DEGREE 5'''\n",
    "X_trainscaledpolytransformer5 = RobustScaler().fit(X_trainpoly5)\n",
    "X_trainscaledpoly5 = X_trainscaledpolytransformer5.transform(X_trainpoly5)\n",
    "\n",
    "X_testscaledpolytransformer5 = RobustScaler().fit(X_testpoly5)\n",
    "X_testscaledpoly5 = X_testscaledpolytransformer5.transform(X_testpoly5)\n",
    "\n",
    "\n",
    "# Compute and print RMSE using your code above on the training set and on the test set\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "'''DEGREE 1'''\n",
    "X_model1 = train_linregmodel(X_trainscaledpoly1, Y_train)\n",
    "X_predictions1 = X_model1.predict(X_trainscaledpoly1)\n",
    "X_rmse1 = rmse(Y_train, X_predictions1)\n",
    "print(\"\\nDegree 1 RMSE: \", X_rmse1)\n",
    "\n",
    "'''DEGREE 2'''\n",
    "X_model2 = train_linregmodel(X_trainscaledpoly2, Y_train)\n",
    "X_predictions2 = X_model2.predict(X_trainscaledpoly2)\n",
    "X_rmse2 = rmse(Y_train, X_predictions2)\n",
    "print(\"\\nDegree 2 RMSE: \", X_rmse2)\n",
    "\n",
    "'''DEGREE 3'''\n",
    "X_model3 = train_linregmodel(X_trainscaledpoly3, Y_train)\n",
    "X_predictions3 = X_model3.predict(X_trainscaledpoly3)\n",
    "X_rmse3 = rmse(Y_train, X_predictions3)\n",
    "print(\"\\nDegree 3 RMSE: \", X_rmse3)\n",
    "\n",
    "'''DEGREE 4'''\n",
    "X_model4 = train_linregmodel(X_trainscaledpoly4, Y_train)\n",
    "X_predictions4 = X_model4.predict(X_trainscaledpoly4)\n",
    "X_rmse4 = rmse(Y_train, X_predictions4)\n",
    "print(\"\\nDegree 4 RMSE: \", X_rmse4)\n",
    "\n",
    "'''DEGREE 5'''\n",
    "X_model5 = train_linregmodel(X_trainscaledpoly5, Y_train)\n",
    "X_predictions5 = X_model5.predict(X_trainscaledpoly5)\n",
    "X_rmse5 = rmse(Y_train, X_predictions5)\n",
    "print(\"\\nDegree 5 RMSE: \", X_rmse5)\n",
    "\n",
    "# Compute and print R^2 on the training set and on the test set\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "'''DEGREE 1'''\n",
    "X_rsq1 = r2_score(Y_train, X_predictions1)\n",
    "print(\"\\nDegree 1 R^2: \", X_rsq1)\n",
    "\n",
    "'''DEGREE 2'''\n",
    "X_rsq2 = r2_score(Y_train, X_predictions2)\n",
    "print(\"\\nDegree 2 R^2: \", X_rsq2)\n",
    "\n",
    "'''DEGREE 3'''\n",
    "X_rsq3 = r2_score(Y_train, X_predictions3)\n",
    "print(\"\\nDegree 3 R^2: \", X_rsq3)\n",
    "\n",
    "'''DEGREE 4'''\n",
    "X_rsq4 = r2_score(Y_train, X_predictions4)\n",
    "print(\"\\nDegree 4 R^2: \", X_rsq4)\n",
    "\n",
    "'''DEGREE 5'''\n",
    "X_rsq5 = r2_score(Y_train, X_predictions5)\n",
    "print(\"\\nDegree 5 R^2: \", X_rsq5)\n",
    "\n",
    "# Generate a plot with the x-axis representing the complexity of the model (i.e. the degree of the polynomial features)\n",
    "# Make the degree range from 1 to 5. The y-axis should represent the RMSE. Plot a line for degree = 1, 2, 3, 4, and 5\n",
    "# for the training error and the test error.\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "plt.plot([1, 2, 3, 4, 5], [X_rmse1, X_rmse2, X_rmse3, X_rmse4, X_rmse5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLG8k-ajdZqW"
   },
   "source": [
    "<span style=\"color:blue\">As visible in the plot, the model that gives the most accurate predictions seems to be the\n",
    "third degree polynomial. This model gives the lowest RMSE and the R^2 closest to 1.\n",
    "As the polynomial degree increases past 3 the model starts to overfit and the error increases.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hdgIABvdZqY",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c5dc39115a9346c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 5. Regularization [2pts]\n",
    "\n",
    "1. Feature selection using regularization\n",
    "2. Training/validation/test split\n",
    "3. Find the optimal parameter for the regularizer\n",
    "4. Compare linear regression with and without regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBaIxTc8H_lS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a938bf9f7024e22",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 5a:\n",
    "Create a function that applies regularization, choose the \\lambda parameter (i.e. the alpha in python) equal to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_bf-aCWqH_lS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb499aece0330317",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def regularization(X, Y, lambd = 500):\n",
    "    model = linear_model.Ridge(alpha = lambd)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kczALy-8dZqZ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f69bcc72259b460",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 5b:\n",
    "Compare the performance of the linear regression with and without regularization. Use the 2 degree polynomial features constructed at question 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sH5XWcISdZqZ",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-039145c67e2bd279",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.09543e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2848.32421789,   3070.863629  ,   5482.55079117,   3740.41434829,\n",
       "         2749.08510722,   2930.82899465,   3603.7364463 ,   5024.70042872,\n",
       "         5075.43961665,   4482.42873864,   5833.2790964 ,   3747.41845701,\n",
       "         2061.88922011,   3605.52512992,   3311.02862537,   2203.45080819,\n",
       "         3429.85491741,   3442.55319103,   2924.533614  ,   7430.71083203,\n",
       "         3359.48967959,   4232.1176464 ,   3561.59630757,   6493.5591696 ,\n",
       "         3291.45307856,   3013.7638149 ,   1632.50905363,   2097.73341236,\n",
       "         4707.12681954,   3891.74967663,   1900.57544878,   2791.38350109,\n",
       "         4542.68401412,   4317.61213261,   3536.4636647 ,   2564.60330595,\n",
       "         2963.73214419,   2976.43922669,   2723.19753161,   2746.40386529,\n",
       "         2066.1152816 ,   5632.13822039,   2692.2326963 ,   3333.66535334,\n",
       "         3509.17625767,   2333.77353887,   4993.22039548,   7830.71635616,\n",
       "         4924.25825636,   5603.73666727,   3052.96452287,   3077.99665842,\n",
       "         5070.27601857,   4255.84350399,   2743.32746919,   3857.28728026,\n",
       "         4366.35447894,   2280.06278178,   2415.50246223,   2312.57072664,\n",
       "         7909.70977051,   4516.89380512,   4928.10766309,   3815.95541819,\n",
       "         5820.89315904,   3941.90406892,   2636.91478841,   2085.08306483,\n",
       "         3984.67987092,  51581.22213588,   8133.08574345,   2884.73696286,\n",
       "         4363.73542108,   2050.53123161,   7989.38091604,   3795.28138051,\n",
       "         5803.30372683,   3391.40478808,   3916.30357783,   3974.84729513,\n",
       "         5186.01652722,   6472.03798399,   2647.01989565,   3378.23785809,\n",
       "         3709.15332822,   3908.72907002,   6834.16776736,   4293.54775601,\n",
       "         4572.04508232,   3765.69928784,   6568.53125342,   2529.84917357,\n",
       "         2990.1530496 ,   3019.79985649,   4382.48988042,   2774.59619796,\n",
       "         3664.29749657,   2488.8337627 ,   3432.11099419,   2571.10551196,\n",
       "         3637.67103083,   3341.33897062,   2751.21863593,   3232.64085063,\n",
       "         2097.32041324,   7407.87854313,   2108.31700722,   3562.42216342,\n",
       "         5639.8395558 ,   4088.32560815,   2852.36608271,   4601.61339733,\n",
       "         2398.70067483,   4194.19999344,   2602.33638267,   2964.28419442,\n",
       "         3807.28950811,   3929.67224152,   2900.90016613,   2507.49607717,\n",
       "         2592.78486843,   3423.02187885,   3281.4877513 ,   2477.87105343,\n",
       "         3951.16374969,   4091.26787463,   3051.48101911,   3711.07214186,\n",
       "         4969.00659891,   2204.66226858,   3792.03973947,   8456.65549091,\n",
       "         4180.842549  ,   5492.06796258,   2662.71249219,   4017.71803841,\n",
       "         3537.31074124,   1610.59233584,   2357.20655533,   5141.41417914,\n",
       "         3296.46269995,   3228.37885334,  11740.9972748 ,   5090.64633877,\n",
       "         3288.6884774 ,   5487.06972801,   4102.97193033,   5275.970736  ,\n",
       "         3221.39500213,   3508.14071618,   4402.13222917,   3825.91274104,\n",
       "         2922.00700151,   2966.96435594,   3449.62741067,   3287.82842818,\n",
       "         3640.48878943,   5026.6509912 ,   5156.10300956,   1933.59727925,\n",
       "         3122.54358474,   3190.99689384,   4198.25095856,   2878.9013677 ,\n",
       "         2630.03171827,   4674.09877435,   3745.59534448,   2445.13376622,\n",
       "         6892.99793771,   4079.77186538,   2852.453169  ,   3022.10972748,\n",
       "         5370.63017896,   2821.77956698,   1748.1399291 ,   2800.79204205,\n",
       "         4150.46966192,   2858.17249768,   2557.20342479,   3643.65339832,\n",
       "         3267.20518778,   3118.1603947 ,   4126.11481743,   2121.56207788,\n",
       "         2763.44686219,   6997.20547216,   3363.64723876,   3735.61273354,\n",
       "         3615.1941225 ,   4006.38628508,   3261.07890416,   3877.99234978,\n",
       "         3622.12407915,   2440.77469156,   2716.05384894,   2662.68009538,\n",
       "         2447.72321693,   3134.84268182,   4345.30305351,   2509.38702976,\n",
       "         5024.04506338,   3133.75827416,   2726.74583149,   3176.66231983,\n",
       "         2963.87306915,   4447.00560912,   4403.760683  ,   2932.47843712,\n",
       "         3146.91203458,   3091.00599437,   3374.28225653,   4268.62970572,\n",
       "         1870.74020308,   2455.91590118,   2627.62997074,   3702.33933467,\n",
       "         -396.35261616,   4116.27892777,   2108.50911962,   4753.11737698,\n",
       "         2251.15652853,   5574.47848844,   3915.45576779,   4297.11778519,\n",
       "         2361.3571351 ,   2514.89142449,   3621.12793438,   2988.18543649,\n",
       "         2299.45095044,   4677.09479866,   3382.44365176,   5881.34674125,\n",
       "         3502.85596096,   9078.2137866 ,   2577.16797904,   3529.75095999,\n",
       "         2819.01187144,   3423.67714665,   4266.25476245,   3596.56702018,\n",
       "         4709.99956812,   4392.90975913,   2642.32944979,   3790.83635591,\n",
       "         3823.57046988,   3638.59159768,   6944.10603214,   3556.61334359,\n",
       "         3868.12469622,   8552.58555426,   3552.8648506 ,   3033.5173192 ,\n",
       "         3587.15031461,   4270.18923682,   6000.98065632,   2603.29096258,\n",
       "         3265.10734172,   3549.33816837,   2540.26530617,   3249.83075267,\n",
       "         3594.99431837,   2501.71824252,   3161.69617465,   3105.66222063,\n",
       "         3341.03625624,   7459.00083658,   2902.47163728,   4447.08403012,\n",
       "         4286.95473728,   5758.14225762,   2207.85581409,   4075.83178701,\n",
       "         4736.8205437 ,   3970.41559732,   9151.6763991 ,   2921.77441443,\n",
       "         2513.08290809,   2565.11413616,   2431.7063971 , 147596.33729458,\n",
       "         3423.61582396,   3084.81492926,   2576.29724075,   6487.13811587,\n",
       "         3283.22436434])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function from 5a for feature selection\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "regu_model = regularization(X_trainscaledpoly2, Y_train)\n",
    "regu_model.predict(X_testscaledpoly2)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EaiaWLs8H_lS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-regularized degree 2 polynomial RMSE\n",
      "Train:  1225.4843223481769\n",
      "Test:   9174.154087499555\n",
      "\n",
      "Regularized: \n",
      "Train:  1376.2639063279169\n",
      "Test:   9085.741464476292\n"
     ]
    }
   ],
   "source": [
    "# Compare the training and test RMSE of the linear regression with and without regularization\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print(\"Non-regularized degree 2 polynomial RMSE\")\n",
    "\n",
    "print(\"Train: \", X_rmse2)\n",
    "\n",
    "X_testscaledpolytransformer2 = RobustScaler().fit(X_testpoly2)\n",
    "X_testscaledpoly2 = X_testscaledpolytransformer2.transform(X_testpoly2)\n",
    "X_predictions2test = X_model2.predict(X_testscaledpoly2)\n",
    "X_rmse2test = rmse(Y_test, X_predictions2test)\n",
    "\n",
    "print(\"Test:  \", X_rmse2test)\n",
    "\n",
    "train_pred_reg = regu_model.predict(X_trainscaledpoly2)\n",
    "test_pred_reg = regu_model.predict(X_testscaledpoly2)\n",
    "\n",
    "# rmse(y_true, y_pred)\n",
    "# mae(y_true, y_pred)\n",
    "\n",
    "print(\"\\nRegularized: \")\n",
    "'''Train RMSE'''\n",
    "print(\"Train: \", rmse(Y_train, train_pred_reg))\n",
    "\n",
    "'''Test RMSE'''\n",
    "print(\"Test:  \", rmse(Y_test, test_pred_reg))\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UWlo7sGUH_lS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found unselected feature\n",
      "Number of features before selection:  91\n",
      "Number of selected features  90\n"
     ]
    }
   ],
   "source": [
    "# Identify how many features were selected (i.e. had a non-zero parameter \\theta) by the regularized model\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "i = 0\n",
    "for feature in regu_model.coef_:\n",
    "    if feature != 0:\n",
    "        i += 1\n",
    "    else:\n",
    "        print(\"Found unselected feature\")\n",
    "\n",
    "print(\"Number of features before selection: \", len(X_model2.coef_))\n",
    "print(\"Number of selected features \", i)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBWaLc9dZqg"
   },
   "source": [
    "<span style=\"color:blue\">The regularized model seems to work slightly worse using the training data. However, it also seems to predict more accurately for unseen data, since the RMSE for the predictions using test data with the regularized model is slightly lower.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6HQ3BpZH_lT",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cff313fb66d82eac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 5c:\n",
    "Compare the coefficients (i.e. the parameters \\theta) of the linear regression models with and without regularization.\n",
    "Plot them in a graph, where the x-axis is the index of a coefficient while the y-axis the magnitute of it. \n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "k2ovwz0PdZql",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e1e400fa5995203",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "plt.plot(range(0, len(X_model2.coef_)), X_model2.coef_, label = 'Degree 2 polynomial model')\n",
    "plt.plot(range(0, len(regu_model.coef_)), regu_model.coef_, label = 'Regularized model')\n",
    "\n",
    "plt.xlabel('Coefficient\\'s index ')\n",
    "plt.ylabel('Magnitude of coefficient')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMJ9JOTNdZq0",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61098ba6c5ba9428",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<span style=\"color:blue\">The coefficients of the 2nd degree polynomial show high variance (showing values between over 10000 and under -10000). After regularizing, the values show far less variance compared to the non-regularized model.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hfx8ACDndZq1",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da1188e07c24903f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 6: Categorical features [3 pts]\n",
    "\n",
    "Load again the entire dataset, without selecting specific features as you did in Part 1. The dataset now contains both *numerical* and *categorical* features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "380x5yjMH_lT",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct65up</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>pctPoverty</th>\n",
       "      <th>pctUnemploy</th>\n",
       "      <th>pctAllDivorc</th>\n",
       "      <th>pctHousOccup</th>\n",
       "      <th>persEmergShelt</th>\n",
       "      <th>persHomeless</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pop</th>\n",
       "      <th>countyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>3.10</td>\n",
       "      <td>21.44</td>\n",
       "      <td>11.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.47</td>\n",
       "      <td>98.37</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1394.59</td>\n",
       "      <td>75122.0</td>\n",
       "      <td>11980.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>2.82</td>\n",
       "      <td>21.30</td>\n",
       "      <td>17.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.42</td>\n",
       "      <td>97.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23123.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>2.76</td>\n",
       "      <td>40.53</td>\n",
       "      <td>12.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.99</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.73</td>\n",
       "      <td>92.45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9988.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA</td>\n",
       "      <td>2.60</td>\n",
       "      <td>27.41</td>\n",
       "      <td>14.42</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.85</td>\n",
       "      <td>7.64</td>\n",
       "      <td>95.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1890.88</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ND</td>\n",
       "      <td>2.46</td>\n",
       "      <td>35.16</td>\n",
       "      <td>8.58</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.68</td>\n",
       "      <td>4.18</td>\n",
       "      <td>8.64</td>\n",
       "      <td>95.07</td>\n",
       "      <td>125</td>\n",
       "      <td>15</td>\n",
       "      <td>4747.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74111.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>MA</td>\n",
       "      <td>2.49</td>\n",
       "      <td>27.70</td>\n",
       "      <td>16.06</td>\n",
       "      <td>99.75</td>\n",
       "      <td>14.28</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.52</td>\n",
       "      <td>92.39</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1623.79</td>\n",
       "      <td>22452.0</td>\n",
       "      <td>92703.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2.71</td>\n",
       "      <td>26.72</td>\n",
       "      <td>8.78</td>\n",
       "      <td>60.02</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.26</td>\n",
       "      <td>90.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5835.29</td>\n",
       "      <td>37594.0</td>\n",
       "      <td>24544.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>CT</td>\n",
       "      <td>2.54</td>\n",
       "      <td>27.72</td>\n",
       "      <td>13.39</td>\n",
       "      <td>100.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.45</td>\n",
       "      <td>10.93</td>\n",
       "      <td>93.85</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>5144.94</td>\n",
       "      <td>35723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ND</td>\n",
       "      <td>2.56</td>\n",
       "      <td>24.03</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.46</td>\n",
       "      <td>5.88</td>\n",
       "      <td>9.20</td>\n",
       "      <td>84.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3817.93</td>\n",
       "      <td>22407.0</td>\n",
       "      <td>13131.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2.57</td>\n",
       "      <td>24.90</td>\n",
       "      <td>15.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.13</td>\n",
       "      <td>8.98</td>\n",
       "      <td>97.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992.98</td>\n",
       "      <td>37664.0</td>\n",
       "      <td>10567.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  perHoush  pct12-29  pct65up  pctUrban  pctPoverty  pctUnemploy  \\\n",
       "0      NJ      3.10     21.44    11.33    100.00        1.96         2.70   \n",
       "1      PA      2.82     21.30    17.18    100.00        3.98         2.43   \n",
       "2      MN      2.76     40.53    12.65      0.00       29.99         9.08   \n",
       "3      MA      2.60     27.41    14.42    100.00        4.01         4.85   \n",
       "4      ND      2.46     35.16     8.58    100.00       13.68         4.18   \n",
       "..    ...       ...       ...      ...       ...         ...          ...   \n",
       "944    MA      2.49     27.70    16.06     99.75       14.28         9.93   \n",
       "945    NJ      2.71     26.72     8.78     60.02        4.58         4.51   \n",
       "946    CT      2.54     27.72    13.39    100.00        6.06         5.45   \n",
       "947    ND      2.56     24.03    12.99      0.00       14.46         5.88   \n",
       "948    NJ      2.57     24.90    15.33    100.00        4.33         4.13   \n",
       "\n",
       "     pctAllDivorc  pctHousOccup  persEmergShelt  persHomeless  nonViolPerPop  \\\n",
       "0            4.47         98.37              11             0        1394.59   \n",
       "1            5.42         97.15               0             0        1955.95   \n",
       "2            9.73         92.45               2             0        9988.79   \n",
       "3            7.64         95.11               0             0        1890.88   \n",
       "4            8.64         95.07             125            15        4747.58   \n",
       "..            ...           ...             ...           ...            ...   \n",
       "944         10.52         92.39              62             1        1623.79   \n",
       "945         12.26         90.52               0             0        5835.29   \n",
       "946         10.93         93.85              64             0        5144.94   \n",
       "947          9.20         84.38               0             0        3817.93   \n",
       "948          8.98         97.03               0             0        1992.98   \n",
       "\n",
       "     medIncome      pop  countyCode  \n",
       "0      75122.0  11980.0        39.0  \n",
       "1          NaN  23123.0        45.0  \n",
       "2          NaN      NaN         7.0  \n",
       "3      42805.0  28700.0        21.0  \n",
       "4          NaN  74111.0        17.0  \n",
       "..         ...      ...         ...  \n",
       "944    22452.0  92703.0         5.0  \n",
       "945    37594.0  24544.0         1.0  \n",
       "946    35723.0      NaN         9.0  \n",
       "947    22407.0  13131.0       105.0  \n",
       "948    37664.0  10567.0        35.0  \n",
       "\n",
       "[949 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path, sep=',', header = 0,\n",
    "                )\n",
    "\n",
    "df.dropna(subset=['nonViolPerPop'],axis=0, inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfFxnBmXH_lU"
   },
   "source": [
    "### Question 6a:\n",
    "Look at the description of the features. Which of the features are or should be treated as categorical? Add the column names in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "l7zA8DugH_lU",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "categorical_features = ['State', 'countyCode']\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKofgW7BH_lU"
   },
   "source": [
    "### Question 6b [Research]:\n",
    "Impute values using the median, on the entire dataset (regardless of train/test split). \n",
    "Does it make sense to impute values for all missing features? If yes, do so. Otherwise explain and drop rows containing missing values you can't replace.\n",
    "\n",
    "Hint: If you want to impute missing values only for some specific columns, you can refer to this link: https://stackoverflow.com/questions/38584184/imputer-on-some-dataframe-columns-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CDiL6DMuH_lU",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan value in  medIncome\n",
      "Found nan value in  pop\n",
      "Found nan value in  countyCode\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def check_for_nan(df):\n",
    "    for col in df:\n",
    "        for item in df[col]:\n",
    "            if pd.isna(item):\n",
    "                print(\"Found nan value in \", col)\n",
    "                break\n",
    "\n",
    "check_for_nan(df)\n",
    "\n",
    "# Impute median on rows found to have NaN values\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "q = imp_median.fit_transform(df[['pop', 'medIncome']]).T\n",
    "df['pop'] = q[0]\n",
    "df['medIncome'] = q[1]\n",
    "\n",
    "# Drop rows with NaN countyCode entries\n",
    "df = df.dropna(subset = ['countyCode'])\n",
    "check_for_nan(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOFCCfP2H_lU"
   },
   "source": [
    "<span style=\"color:blue\">In this example of categorical features it does not make sense to impute all missing features. In the case of the countyCode, some states have more counties than other states. If the median of the countyCode of all states is 40 but a state only has less than 40 counties it is impossible to fill the missing feature with that median.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGSSS-7PH_lU"
   },
   "source": [
    "### Question 6c:\n",
    "Have another look at the data, specifically the two new added features. Do you consider them useful/meaningful predictors for a (linear) Logistic Regression model? Explain.\n",
    "\n",
    "Can you think of doing something that can help a linear model take advantage of some additional information? If so, implement your solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "cXW8xPbUH_lU",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoUNKbnsH_lV"
   },
   "source": [
    "<span style=\"color:blue\">We can use non-continuous variables in our model features by using one-hot encoding for example. This can give more insight into the importance of these variables.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuU-gyqAH_lV"
   },
   "source": [
    "### Question 6d:\n",
    "One hot encode the categorical features, then merge them back into the original dataframe/array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S2VNmYKSH_lV",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct65up</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>pctPoverty</th>\n",
       "      <th>pctUnemploy</th>\n",
       "      <th>pctAllDivorc</th>\n",
       "      <th>pctHousOccup</th>\n",
       "      <th>persEmergShelt</th>\n",
       "      <th>...</th>\n",
       "      <th>750.0</th>\n",
       "      <th>760.0</th>\n",
       "      <th>770.0</th>\n",
       "      <th>775.0</th>\n",
       "      <th>790.0</th>\n",
       "      <th>800.0</th>\n",
       "      <th>810.0</th>\n",
       "      <th>820.0</th>\n",
       "      <th>830.0</th>\n",
       "      <th>840.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>3.10</td>\n",
       "      <td>21.44</td>\n",
       "      <td>11.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.47</td>\n",
       "      <td>98.37</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>2.82</td>\n",
       "      <td>21.30</td>\n",
       "      <td>17.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.42</td>\n",
       "      <td>97.15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>2.76</td>\n",
       "      <td>40.53</td>\n",
       "      <td>12.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.99</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.73</td>\n",
       "      <td>92.45</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA</td>\n",
       "      <td>2.60</td>\n",
       "      <td>27.41</td>\n",
       "      <td>14.42</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.85</td>\n",
       "      <td>7.64</td>\n",
       "      <td>95.11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ND</td>\n",
       "      <td>2.46</td>\n",
       "      <td>35.16</td>\n",
       "      <td>8.58</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.68</td>\n",
       "      <td>4.18</td>\n",
       "      <td>8.64</td>\n",
       "      <td>95.07</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>MA</td>\n",
       "      <td>2.49</td>\n",
       "      <td>27.70</td>\n",
       "      <td>16.06</td>\n",
       "      <td>99.75</td>\n",
       "      <td>14.28</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.52</td>\n",
       "      <td>92.39</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2.71</td>\n",
       "      <td>26.72</td>\n",
       "      <td>8.78</td>\n",
       "      <td>60.02</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.26</td>\n",
       "      <td>90.52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>CT</td>\n",
       "      <td>2.54</td>\n",
       "      <td>27.72</td>\n",
       "      <td>13.39</td>\n",
       "      <td>100.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.45</td>\n",
       "      <td>10.93</td>\n",
       "      <td>93.85</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ND</td>\n",
       "      <td>2.56</td>\n",
       "      <td>24.03</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.46</td>\n",
       "      <td>5.88</td>\n",
       "      <td>9.20</td>\n",
       "      <td>84.38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2.57</td>\n",
       "      <td>24.90</td>\n",
       "      <td>15.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.13</td>\n",
       "      <td>8.98</td>\n",
       "      <td>97.03</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows  150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  perHoush  pct12-29  pct65up  pctUrban  pctPoverty  pctUnemploy  \\\n",
       "0      NJ      3.10     21.44    11.33    100.00        1.96         2.70   \n",
       "1      PA      2.82     21.30    17.18    100.00        3.98         2.43   \n",
       "2      MN      2.76     40.53    12.65      0.00       29.99         9.08   \n",
       "3      MA      2.60     27.41    14.42    100.00        4.01         4.85   \n",
       "4      ND      2.46     35.16     8.58    100.00       13.68         4.18   \n",
       "..    ...       ...       ...      ...       ...         ...          ...   \n",
       "944    MA      2.49     27.70    16.06     99.75       14.28         9.93   \n",
       "945    NJ      2.71     26.72     8.78     60.02        4.58         4.51   \n",
       "946    CT      2.54     27.72    13.39    100.00        6.06         5.45   \n",
       "947    ND      2.56     24.03    12.99      0.00       14.46         5.88   \n",
       "948    NJ      2.57     24.90    15.33    100.00        4.33         4.13   \n",
       "\n",
       "     pctAllDivorc  pctHousOccup  persEmergShelt  ...  750.0  760.0  770.0  \\\n",
       "0            4.47         98.37              11  ...      0      0      0   \n",
       "1            5.42         97.15               0  ...      0      0      0   \n",
       "2            9.73         92.45               2  ...      0      0      0   \n",
       "3            7.64         95.11               0  ...      0      0      0   \n",
       "4            8.64         95.07             125  ...      0      0      0   \n",
       "..            ...           ...             ...  ...    ...    ...    ...   \n",
       "944         10.52         92.39              62  ...      0      0      0   \n",
       "945         12.26         90.52               0  ...      0      0      0   \n",
       "946         10.93         93.85              64  ...      0      0      0   \n",
       "947          9.20         84.38               0  ...      0      0      0   \n",
       "948          8.98         97.03               0  ...      0      0      0   \n",
       "\n",
       "     775.0  790.0  800.0  810.0  820.0  830.0  840.0  \n",
       "0        0      0      0      0      0      0      0  \n",
       "1        0      0      0      0      0      0      0  \n",
       "2        0      0      0      0      0      0      0  \n",
       "3        0      0      0      0      0      0      0  \n",
       "4        0      0      0      0      0      0      0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...  \n",
       "944      0      0      0      0      0      0      0  \n",
       "945      0      0      0      0      0      0      0  \n",
       "946      0      0      0      0      0      0      0  \n",
       "947      0      0      0      0      0      0      0  \n",
       "948      0      0      0      0      0      0      0  \n",
       "\n",
       "[921 rows x 150 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "state = pd.get_dummies(df.State)\n",
    "df = df.join(state)\n",
    "\n",
    "countycode = pd.get_dummies(df.countyCode)\n",
    "df = df.join(countycode)\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = df.drop(columns=['State', 'countyCode'])\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLAjyUxKH_lV"
   },
   "source": [
    "### Question 6e:\n",
    "Follow the instructions in the cell below. Due to randomization of the train_test_split, results might change. Make sure to **run the same code a few times** and understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Ff1HfQ3jH_lV",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136308\n",
      "108928\n",
      "13616\n",
      "13764\n",
      "Errors for Train: \n",
      "R^2:  0.5448827639643462\n",
      "RMSE:  1545.7796673073028\n",
      "Errors for test: \n",
      "R^2:  0.4310005071911249\n",
      "RMSE:  1708.311816427893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>R^2</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.453860</td>\n",
       "      <td>1924.872392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.453561</td>\n",
       "      <td>1925.397905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>1925.562943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.452886</td>\n",
       "      <td>1926.586974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.452271</td>\n",
       "      <td>1927.670750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.451673</td>\n",
       "      <td>1928.721786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.451111</td>\n",
       "      <td>1929.710419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.450587</td>\n",
       "      <td>1930.630472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>1930.764408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.450101</td>\n",
       "      <td>1931.484655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>0.446596</td>\n",
       "      <td>1937.631104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>0.444282</td>\n",
       "      <td>1941.677780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>0.442468</td>\n",
       "      <td>1944.843016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>0.440947</td>\n",
       "      <td>1947.495564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>0.439628</td>\n",
       "      <td>1949.791125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70</td>\n",
       "      <td>0.438465</td>\n",
       "      <td>1951.813784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80</td>\n",
       "      <td>0.437427</td>\n",
       "      <td>1953.616983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>0.436492</td>\n",
       "      <td>1955.238347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>0.435646</td>\n",
       "      <td>1956.706112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120</td>\n",
       "      <td>0.434169</td>\n",
       "      <td>1959.264801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>140</td>\n",
       "      <td>0.432921</td>\n",
       "      <td>1961.424018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>170</td>\n",
       "      <td>0.431371</td>\n",
       "      <td>1964.103310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>0.430107</td>\n",
       "      <td>1966.285819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>250</td>\n",
       "      <td>0.428439</td>\n",
       "      <td>1969.160470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>300</td>\n",
       "      <td>0.427144</td>\n",
       "      <td>1971.390067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>400</td>\n",
       "      <td>0.425219</td>\n",
       "      <td>1974.699101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>500</td>\n",
       "      <td>0.423798</td>\n",
       "      <td>1977.138350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>600</td>\n",
       "      <td>0.422651</td>\n",
       "      <td>1979.106235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>700</td>\n",
       "      <td>0.421663</td>\n",
       "      <td>1980.798212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>800</td>\n",
       "      <td>0.420775</td>\n",
       "      <td>1982.318943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>900</td>\n",
       "      <td>0.419951</td>\n",
       "      <td>1983.728124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.419171</td>\n",
       "      <td>1985.061474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda       R^2         RMSE\n",
       "0        3  0.453860  1924.872392\n",
       "1        2  0.453561  1925.397905\n",
       "2        4  0.453468  1925.562943\n",
       "3        5  0.452886  1926.586974\n",
       "4        6  0.452271  1927.670750\n",
       "5        7  0.451673  1928.721786\n",
       "6        8  0.451111  1929.710419\n",
       "7        9  0.450587  1930.630472\n",
       "8        1  0.450511  1930.764408\n",
       "9       10  0.450101  1931.484655\n",
       "10      20  0.446596  1937.631104\n",
       "11      30  0.444282  1941.677780\n",
       "12      40  0.442468  1944.843016\n",
       "13      50  0.440947  1947.495564\n",
       "14      60  0.439628  1949.791125\n",
       "15      70  0.438465  1951.813784\n",
       "16      80  0.437427  1953.616983\n",
       "17      90  0.436492  1955.238347\n",
       "18     100  0.435646  1956.706112\n",
       "19     120  0.434169  1959.264801\n",
       "20     140  0.432921  1961.424018\n",
       "21     170  0.431371  1964.103310\n",
       "22     200  0.430107  1966.285819\n",
       "23     250  0.428439  1969.160470\n",
       "24     300  0.427144  1971.390067\n",
       "25     400  0.425219  1974.699101\n",
       "26     500  0.423798  1977.138350\n",
       "27     600  0.422651  1979.106235\n",
       "28     700  0.421663  1980.798212\n",
       "29     800  0.420775  1982.318943\n",
       "30     900  0.419951  1983.728124\n",
       "31    1000  0.419171  1985.061474"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Performance for best test with Regularization: \n",
      "R^2:  0.5047196567588331\n",
      "RMSE:  1642.5112622995327\n",
      "Performance without regularization : \n",
      "R^2:  0.5448827639643462\n",
      "RMSE:  1545.7796673073028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "# Split the dataset into training, validation and test sets:\n",
    "# Training set: 10% of the entire set\n",
    "# Make the remaining 10% a validation dataset and the rest a test set.\n",
    "\n",
    "### BEGIN SOLUTION ###\n",
    "X = df.loc[:, df.columns != 'nonViolPerPop'].to_numpy()\n",
    "Y = df['nonViolPerPop'].to_numpy()\n",
    "\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "\n",
    "# Produces test split.\n",
    "x_remaining, x_test, y_remaining, y_test = train_test_split(\n",
    "    X, Y, test_size = ratio_test)\n",
    "\n",
    "# Adjusts val ratio according to remaining dataset.\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_adj = ratio_val / ratio_remaining\n",
    "\n",
    "# Make train and val splits.\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_remaining, y_remaining, test_size = ratio_adj)\n",
    "\n",
    "print(df.size)\n",
    "print(x_train.size + y_train.size)\n",
    "print(x_val.size + y_val.size)\n",
    "print(x_test.size + y_test.size)\n",
    "### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Normalize all features based on the training and validation set combined.\n",
    "\n",
    "### BEGIN SOLUTION ###\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "val_and_train = np.vstack((x_train, x_val))\n",
    "\n",
    "transformer = Normalizer().fit(val_and_train)\n",
    "x_train_norm = transformer.transform(x_train)\n",
    "x_val_norm = transformer.transform(x_val)\n",
    "x_test_norm = transformer.transform(x_test)\n",
    "### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Train a linear regression model on the training and validation set combined. \n",
    "# Calculate the error on the training set and the test set.\n",
    "\n",
    "### BEGIN SOLUTION ###\n",
    "val_and_train_norm = np.vstack((x_train_norm, x_val_norm))\n",
    "\n",
    "expected_values = np.append(y_train, y_val)\n",
    "\n",
    "model = train_linregmodel(val_and_train_norm, expected_values)\n",
    "train_predictions = model.predict(x_train_norm)\n",
    "test_predictions = model.predict(x_test_norm)\n",
    "\n",
    "rsq_train = r2_score(y_train, train_predictions)\n",
    "rmse_train = rmse(y_train, train_predictions)\n",
    "print(\"Errors for Train: \")\n",
    "print(\"R^2: \", rsq_train)\n",
    "print(\"RMSE: \", rmse_train)\n",
    "\n",
    "rsq_test = r2_score(y_test, test_predictions)\n",
    "rmse_test = rmse(y_test, test_predictions)\n",
    "print(\"Errors for test: \")\n",
    "print(\"R^2: \", rsq_test)\n",
    "print(\"RMSE: \", rmse_test)\n",
    "### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Train a regularized model (use Ridge regularization). To decide the parameter alpha, use a range of values to train,\n",
    "# the model. Test its performance on the validation set. Output the RMSE for different values of alpha, and choose the\n",
    "# best value.\n",
    "\n",
    "### BEGIN SOLUTION ###\n",
    "lambdalist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 170, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "lambdaeffects = pd.DataFrame()\n",
    "lambdaeffects['lambda'] = lambdalist\n",
    "\n",
    "rsqs = []\n",
    "rmses = []\n",
    "for lmbd in lambdalist:\n",
    "    reg_model = regularization(x_train, y_train, lmbd)\n",
    "    reg_predictions = reg_model.predict(x_val)\n",
    "\n",
    "    rsq_reg = r2_score(y_val, reg_predictions)\n",
    "    rmse_reg = rmse(y_val, reg_predictions)\n",
    "    \n",
    "    rsqs.append(rsq_reg)\n",
    "    rmses.append(rmse_reg)\n",
    "    \n",
    "lambdaeffects['R^2'] = rsqs\n",
    "lambdaeffects['RMSE'] = rmses\n",
    "### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Train the regularized model (use Ridge regularization) with the best alpha parameter found above on the traing and \n",
    "# validation set combined.\n",
    "\n",
    "### BEGIN SOLUTION ###\n",
    "top_lambdas = lambdaeffects.reindex(lambdaeffects.RMSE.abs().sort_values(ascending = True).index)\n",
    "top_lambdas.index = range(0, len(top_lambdas))\n",
    "display(top_lambdas)\n",
    "print(top_lambdas['lambda'][0])\n",
    "\n",
    "best_model = regularization(x_train, y_train, top_lambdas['lambda'][0])\n",
    "best_predictions = best_model.predict(np.vstack((x_train, x_val)))\n",
    "best_expected = np.append(y_train, y_val)\n",
    "\n",
    "best_rsq = r2_score(best_expected, best_predictions)\n",
    "best_rmse = rmse(best_expected, best_predictions)\n",
    "print(\"Performance for best test with Regularization: \")\n",
    "print(\"R^2: \", best_rsq)\n",
    "print(\"RMSE: \", best_rmse)\n",
    "\n",
    "print(\"Performance without regularization : \")\n",
    "print(\"R^2: \", rsq_train)\n",
    "print(\"RMSE: \", rmse_train)\n",
    "### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Compare the performance of the linear regression with and without regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23xaVneOdZrC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a93fd8e5829ee29a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 6f:\n",
    "What are your conclusions for the two models compared? Which model should you choose over the two? Is hyperparameter tuning useful in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_L6IfD2dZrC",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d199066f44b9fd5",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "<span style=\"color:blue\">The performance of the model without regularization seems to consistently outperform the model with regularization. For this specific case, the non-regularized model seems to be the better choice. Hyperparameter tuning is useful, since it results in the lambda value which gives the best performing model. However the regularized model is outperformed in this case, making hyperparameter tuning unnecessary.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "Practical Assignment 1 - 2021 Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
